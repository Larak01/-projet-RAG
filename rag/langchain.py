# ğŸ“š Projet RAG â€” Retrieval-Augmented Generation

Ce projet met en Å“uvre une architecture **RAG (Retrieval-Augmented Generation)** pour amÃ©liorer la qualitÃ© des rÃ©ponses gÃ©nÃ©rÃ©es par des modÃ¨les de langage (LLM). Lâ€™approche repose sur lâ€™extraction automatique de contenu documentaire pertinent pour rÃ©duire les hallucinations.

---

## ğŸ¯ Objectifs pÃ©dagogiques

- âš™ï¸ ImplÃ©menter une architecture RAG fonctionnelle (embeddings + moteur vectoriel + LLM)
- ğŸ’¡ Comparer deux frameworks : **LangChain** et **LlamaIndex**
- ğŸ–¥ï¸ CrÃ©er une interface utilisateur interactive avec **Streamlit**
- ğŸŒ IntÃ©grer la **multilingue**, **personnalisation dynamique** et **feedback utilisateur**

---

## âœ… FonctionnalitÃ©s principales

- ğŸ“„ Upload de fichiers PDF avec vectorisation automatique
- â“ SystÃ¨me de question-rÃ©ponse avec injection de contexte
- ğŸ§  Choix du framework : `LangChain` ou `LlamaIndex`
- ğŸŒ SÃ©lecteur de langue : FranÃ§ais, Anglais, Espagnol, Japonais
- ğŸ› ï¸ ParamÃ©trage dynamique du nombre de documents rÃ©cupÃ©rÃ©s (`top_k`)
- ğŸ“ Feedback utilisateur avec `st.radio` et enregistrement en base SQLite
- ğŸ” Connexion sÃ©curisÃ©e Ã  **Azure OpenAI** pour le LLM et les embeddings

---

## ğŸš€ Lancer l'application localement

```bash
git clone https://github.com/Larak01/projet-RAG.git
cd projet-RAG
pip install -r requirements.txt
streamlit run app.py
```

> ğŸ§  Ce projet utilise **Azure OpenAI** pour accÃ©der aux modÃ¨les `gpt-35-turbo` et `text-embedding-ada-002`. Les paramÃ¨tres API sont stockÃ©s localement dans un fichier `config.toml` (non inclus dans le dÃ©pÃ´t).

---

## ğŸ—„ï¸ Structure du projet

```
projet-RAG/
â”‚
â”œâ”€â”€ app.py                      # Application principale Streamlit
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ README.md                  # Ce fichier
â”œâ”€â”€ samples/                   # Fichiers PDF de dÃ©monstration
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ langchain.py           # Pipeline utilisant LangChain
â”‚   â””â”€â”€ llamaindex.py          # Pipeline utilisant LlamaIndex
â”œâ”€â”€ pages/feedback.py          # Page dÃ©diÃ©e Ã  l'analyse des retours utilisateur
â””â”€â”€ feedback.db                # Base SQLite pour stocker les feedbacks
```

---

## ğŸ” Configuration locale

CrÃ©er un fichier `config.toml` (non versionnÃ©) contenant vos identifiants Azure OpenAI :

```toml
[chat]
azure_deployment = "gpt-chat"
azure_api_key = "sk-..."
azure_endpoint = "https://projet-rag-openai.azure.com/"
azure_api_version = "2023-12-01-preview"

[embedding]
azure_deployment = "embed-ada"
azure_api_key = "sk-..."
azure_endpoint ="https://projet-rag-openai.azure.com/"
azure_api_version = "2023-12-01-preview"
```


---

## ğŸ’¡ DÃ©ploiement sur Streamlit Cloud

1. CrÃ©e un compte sur https://streamlit.io/cloud
2. Connecte ton dÃ©pÃ´t GitHub
3. Ajoute tes secrets dans `Settings > Secrets` de l'app

---

## ğŸ“¬ Contact

Pour toute question, contactez [Larak01](https://github.com/Larak01).

Bon RAG avec Azure OpenAI ! ğŸ‰
