# ğŸ“š Projet RAG â€” Retrieval-Augmented Generation

Ce projet met en Å“uvre une architecture **RAG (Retrieval-Augmented Generation)**, un cadre qui amÃ©liore la qualitÃ© des rÃ©ponses gÃ©nÃ©rÃ©es par les modÃ¨les de langage (LLM) en y intÃ©grant automatiquement du **contenu extrait de documents** pertinents. Cette approche permet de **rÃ©duire les hallucinations** en sâ€™appuyant sur une base de connaissances documentaire comme support contextuel.

---

## ğŸ¯ Objectif pÃ©dagogique

Ce projet a pour objectifs :

- âš™ï¸ ImplÃ©menter une architecture **RAG** fonctionnelle, combinant embeddings, moteur de recherche vectorielle et LLM
- ğŸ’¡ Explorer deux frameworks : **LangChain** et **LlamaIndex**
- ğŸ–¥ï¸ DÃ©ployer une **interface utilisateur interactive** via **Streamlit**
- ğŸ” ExpÃ©rimenter des **amÃ©liorations ciblÃ©es** du RAG : multilingue, feedback utilisateur, moteur hybride, paramÃ©trage dynamique


## âœ… FonctionnalitÃ©s clÃ©s

- Upload et vectorisation de fichiers PDF
- Question-answering contextuel
- SÃ©lecteur de framework (LangChain / LlamaIndex)
- Choix de la langue de rÃ©ponse
- Feedback utilisateur enregistrÃ© en base SQLite
- ParamÃ©trage du nombre de documents Ã  utiliser (`top_k`)

## ğŸš€ Lancer l'application localement

```bash
git clone https://github.com/Larak01/-projet-RAG.git
cd -projet-RAG
pip install -r requirements.txt
streamlit run app.py

## ğŸŒ Application dÃ©ployÃ©e

ğŸ‘‰ AccÃ©dez Ã  lâ€™application ici : [https://projet-rag-larak01.streamlit.app](https://projet-rag-larak01.streamlit.app)


