# ğŸ“š Projet RAG â€” Retrieval-Augmented Generation

Ce projet met en Å“uvre une architecture **RAG (Retrieval-Augmented Generation)** pour amÃ©liorer la qualitÃ© des rÃ©ponses gÃ©nÃ©rÃ©es par des modÃ¨les de langage (LLM). Lâ€™approche repose sur lâ€™extraction automatique de contenu documentaire pertinent pour rÃ©duire les hallucinations.

---

## ğŸ¯ Ce que j'ai rÃ©alisÃ© dans ce projet

- ğŸ”§ J'ai intÃ©grÃ© **deux frameworks** RAG au choix : **LangChain** et **LlamaIndex**
- ğŸ“ J'ai ajoutÃ© une interface d'upload de fichiers PDF avec vectorisation automatique
- ğŸ”¤ J'ai ajoutÃ© un **sÃ©lecteur de langue de rÃ©ponse** multilingue : FranÃ§ais, Anglais, Espagnol, Japonais
- ğŸ” J'ai intÃ©grÃ© un **slider** permettant de choisir dynamiquement combien de documents (`k`) sont rÃ©cupÃ©rÃ©s par la recherche vectorielle
- ğŸ§ª J'ai implÃ©mentÃ© un systÃ¨me de **feedback utilisateur** via `st.radio` puis sauvegardÃ© les rÃ©ponses dans une base **SQLite**
- ğŸ§  J'ai utilisÃ© **Azure OpenAI** comme fournisseur de LLM et d'embeddings
- â˜ï¸ J'ai configurÃ© deux **dÃ©ploiements personnalisÃ©s** sur Azure :
  - `gpt-35-turbo` (dÃ©ployÃ© sous le nom `gpt-chat`) pour les rÃ©ponses du chatbot
  - `text-embedding-ada-002` (dÃ©ployÃ© sous le nom `embed-ada`) pour la vectorisation des documents
- ğŸ” Jâ€™ai appris Ã  sÃ©curiser mes clÃ©s API via `st.secrets` sur Streamlit Cloud

---

## âœ… FonctionnalitÃ©s principales

- ğŸ“„ Upload de fichiers PDF avec vectorisation automatique
- â“ SystÃ¨me de question-rÃ©ponse avec injection de contexte
- ğŸ§  Choix du framework : `LangChain` ou `LlamaIndex`
- ğŸŒ SÃ©lecteur de langue : FranÃ§ais, Anglais, Espagnol, Japonais
- ğŸ› ï¸ ParamÃ©trage dynamique du nombre de documents rÃ©cupÃ©rÃ©s (`top_k`)
- ğŸ“ Feedback utilisateur avec `st.radio` et enregistrement en base SQLite
- ğŸ” Connexion sÃ©curisÃ©e Ã  **Azure OpenAI** pour le LLM et les embeddings
- ğŸ“¦ Utilisation de deux modÃ¨les Azure dÃ©ployÃ©s manuellement :
  - `gpt-35-turbo` pour le chat (`gpt-chat`)
  - `text-embedding-ada-002` pour les embeddings (`embed-ada`)

---

## ğŸš€ Lancer l'application localement

```bash
git clone "https://github.com/Larak01/projet-RAG.git"
cd projet-RAG
pip install -r requirements.txt
streamlit run app.py
```

> ğŸ§  Ce projet utilise **Azure OpenAI** pour accÃ©der aux modÃ¨les `gpt-35-turbo` et `text-embedding-ada-002`. Les paramÃ¨tres API sont stockÃ©s localement dans un fichier `config.toml` (non inclus dans le dÃ©pÃ´t) ou gÃ©rÃ©s dans `st.secrets` si dÃ©ployÃ© sur Streamlit Cloud.

---

## ğŸ—„ï¸ Structure du projet

```
projet-RAG/
â”‚
â”œâ”€â”€ app.py                      # Application principale Streamlit
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ README.md                  # Ce fichier
â”œâ”€â”€ samples/                   # Fichiers PDF de dÃ©monstration
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ langchain.py           # Pipeline utilisant LangChain
â”‚   â””â”€â”€ llamaindex.py          # Pipeline utilisant LlamaIndex
â”œâ”€â”€ pages/feedback.py          # Page dÃ©diÃ©e Ã  l'analyse des retours utilisateur
â””â”€â”€ feedback.db                # Base SQLite pour stocker les feedbacks
```


---

## ğŸ’¡ DÃ©ploiement sur Streamlit Cloud

1. CrÃ©e un compte: "https://share.streamlit.io/user/larak01"
2. Connecte mon dÃ©pÃ´t GitHub
3. Ajoute mes secrets dans `Settings > Secrets` de l'app

---

## ğŸ“¬ Contact

Pour toute question, contactez [Larak01](https://github.com/Larak01).

Bon RAG avec Azure OpenAI ! ğŸ‰
