# projet RAG
# ğŸ“š RAG UI â€” Retrieval-Augmented Generation avec LangChain & LlamaIndex

Ce projet implÃ©mente une interface RAG (Retrieval-Augmented Generation) permettant de questionner le contenu de documents PDF. Il sâ€™appuie sur des embeddings et modÃ¨les de chat OpenAI dÃ©ployÃ©s sur Azure, et propose deux versions du moteur RAG : via **LangChain** et via **LlamaIndex**.

---

## ğŸ” Objectif pÃ©dagogique

Ce projet est rÃ©alisÃ© dans le cadre du module "Hands-on Project" (MAG 3). Il a pour but de :
- ImplÃ©menter une architecture RAG fonctionnelle
- Comparer deux frameworks (LangChain vs LlamaIndex)
- DÃ©ployer une interface interactive via Streamlit
- Explorer des pistes dâ€™amÃ©lioration (langue, feedback, top-kâ€¦)

---

## ğŸ“ Structure du projet


---

## âš™ï¸ PrÃ©requis techniques

- Python 3.10+
- AccÃ¨s Ã  Azure OpenAI avec :
  - Un modÃ¨le d'embedding (`text-embedding-ada-002` ou autre)
  - Un modÃ¨le de chat (`gpt-35-turbo`, `gpt-4`, etc.)
- Un environnement virtuel Python (recommandÃ©)

---

## ğŸ” Configuration Azure (secrets/config.yaml)

CrÃ©er un fichier `secrets/config.yaml` **(non versionnÃ©)** :

```yaml
embedding:
  azure_endpoint: "https://mon-endpoint.openai.azure.com/"
  azure_deployment: "embedding-model"
  azure_api_version: "2023-05-15"
  azure_api_key: "ma-cle-api"

chat:
  azure_endpoint: "https://mon-endpoint.openai.azure.com/"
  azure_deployment: "chat-model"
  azure_api_version: "2023-05-15"
  azure_api_key: "ma-cle-api"
